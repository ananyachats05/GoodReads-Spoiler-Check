{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O1Wk9_uMdD4",
        "outputId": "0ada5984-b029-4ed6-c7a5-b8fe8b81cabd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ2qxhyUbHLY",
        "outputId": "a2a171d9-099e-4833-b740-66c4f64698f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ref                                                            title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "lainguyn123/student-performance-factors                        Student Performance Factors                          94KB  2024-09-02 10:53:57          23440        424  1.0              \n",
            "abdulszz/spotify-most-streamed-songs                           Spotify Most Streamed Songs                          60KB  2024-09-07 18:23:14           8235        104  1.0              \n",
            "ayushi10kumari/top-rated-movie-dataset                         Top Rated Movie Dataset                               1MB  2024-09-07 17:38:12           2040         23  0.9411765        \n",
            "valakhorasani/electric-vehicle-charging-patterns               Electric Vehicle Charging Patterns                  130KB  2024-10-02 10:52:27            932         31  1.0              \n",
            "shreyasur965/recent-earthquakes                                Global Earthquake Data                              214KB  2024-09-19 16:18:55           1139         21  1.0              \n",
            "valakhorasani/mobile-device-usage-and-user-behavior-dataset    Mobile Device Usage and User Behavior Dataset        11KB  2024-09-28 20:21:12           1697         46  1.0              \n",
            "aaditya1gautam/tmdb-top-rated-9000-movies-dataset              TMDB Top Rated 9000 Movies Dataset                    1MB  2024-09-25 05:48:09            834         22  0.9411765        \n",
            "waqi786/remote-work-and-mental-health                          Remote Work & Mental Health üåçüß†                       93KB  2024-09-22 11:44:29           3336         62  1.0              \n",
            "owm4096/laptop-prices                                          Laptop Prices                                        25KB  2024-09-09 12:43:01           7539        107  1.0              \n",
            "asmonline/spotify-song-performance-dataset                     Spotify's Most Streamed Songs 2024                   55KB  2024-09-23 21:06:36           1474         21  0.9411765        \n",
            "jayavarman/bike-sales-data-of-100k                             Bike Sales Data of 100k                               2MB  2024-09-26 07:50:13           1575         26  1.0              \n",
            "dongrelaxman/amazon-reviews-dataset                            Amazon Reviews Dataset                                5MB  2024-09-20 06:07:43           1103         29  1.0              \n",
            "cameronseamons/electronic-sales-sep2023-sep2024                Customer purchase behavior - Electronic Sales Data  327KB  2024-09-23 01:54:36           3065         48  1.0              \n",
            "kamalisrani/mens-t20-cwc-dataset-2007-2004                     Men's T20 CWC Dataset 2007-2024                      25KB  2024-09-17 16:36:33            836         22  1.0              \n",
            "taweilo/mba-admission-dataset                                  MBA Admission dataset, Class 2025                    55KB  2024-09-18 07:57:38           3472         59  1.0              \n",
            "adarshde/wine-quality-dataset                                  Wine Quality dataset                                 32KB  2024-10-01 16:40:57            892         25  1.0              \n",
            "syedfaizanalii/predict-students-dropout-and-academic-success   Predict Students Dropout and Academic Success       105KB  2024-09-28 09:41:55            930         42  1.0              \n",
            "iamtanmayshukla/2024-u-s-election-generic-ballot-polling-data  2024 USA Election Polling Data                       25KB  2024-08-20 22:34:30            441        323  1.0              \n",
            "faresashraf1001/supermarket-sales                              Supermarket Sales Dataset                            37KB  2024-09-19 22:44:01           2018         29  0.88235295       \n",
            "mrmars1010/iphone-customer-reviews-nlp                         IPhone Customer Reviews | NLP                       350KB  2024-09-22 02:14:40           2119         37  1.0              \n"
          ]
        }
      ],
      "source": [
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zc4CmieacpO",
        "outputId": "c18ec3b4-8546-4782-e92c-61d88aa8a6f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/pypiahmad/goodreads-book-reviews\n",
            "License(s): apache-2.0\n",
            "goodreads-book-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  goodreads-book-reviews.zip\n",
            "replace goodreads_reviews_dedup.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "\n",
        "!kaggle datasets download -d pypiahmad/goodreads-book-reviews\n",
        "!unzip goodreads-book-reviews.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "bVceUiQNacrJ",
        "outputId": "90d9fd41-0e63-4af9-e4b5-42f89bab81c8"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6ddfaca328c2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'goodreads_reviews_spoiler.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m                         \u001b[0mdata_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1403\u001b[0;31m                 \u001b[0mujson_loads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m             )\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_json('goodreads_reviews_spoiler.json', lines = True)\n",
        "df.head()\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMCwOcpxactZ",
        "outputId": "268b0459-0f7d-4252-eb4e-32393aac3e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1378033 entries, 0 to 1378032\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count    Dtype         \n",
            "---  ------            --------------    -----         \n",
            " 0   user_id           1378033 non-null  object        \n",
            " 1   timestamp         1378033 non-null  datetime64[ns]\n",
            " 2   review_sentences  1378033 non-null  object        \n",
            " 3   rating            1378033 non-null  int64         \n",
            " 4   has_spoiler       1378033 non-null  bool          \n",
            " 5   book_id           1378033 non-null  int64         \n",
            " 6   review_id         1378033 non-null  object        \n",
            "dtypes: bool(1), datetime64[ns](1), int64(2), object(3)\n",
            "memory usage: 64.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "Ysv9Tustacw6",
        "outputId": "25dc0aa1-edf8-44cf-ff75-9d02fb0a2606"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>has_spoiler</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>1288406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>89627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "has_spoiler\n",
              "False    1288406\n",
              "True       89627\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['has_spoiler'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F63ZIiK_oEch",
        "outputId": "62c58036-dd3d-44ec-e3f5-0dd93f732a36"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-33-c584072d1c11>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['cleaned_text'].fillna('', inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of empty documents in training set after cleaning: 0\n",
            "Number of empty documents in testing set after cleaning: 0\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def clean_text(sentences):\n",
        "    cleaned_sentences = []\n",
        "    for sentence in sentences:\n",
        "        if isinstance(sentence, str):\n",
        "            sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
        "            sentence = sentence.lower()\n",
        "            sentence = ' '.join([word for word in sentence.split() if word not in stopwords.words('english')])\n",
        "        cleaned_sentences.append(sentence)\n",
        "    return cleaned_sentences\n",
        "\n",
        "df['cleaned_text'] = df['review_sentences'].apply(clean_text)\n",
        "df['cleaned_text'].fillna('', inplace=True)\n",
        "\n",
        "X_train = df['cleaned_text'].astype(str).tolist()\n",
        "X_test = df['cleaned_text'].astype(str).tolist()\n",
        "\n",
        "# Recheck for empty documents again\n",
        "empty_docs_train = [doc for doc in X_train if len(doc.strip()) == 0]\n",
        "empty_docs_test = [doc for doc in X_test if len(doc.strip()) == 0]\n",
        "\n",
        "print(f\"Number of empty documents in training set after cleaning: {len(empty_docs_train)}\")\n",
        "print(f\"Number of empty documents in testing set after cleaning: {len(empty_docs_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm0ZYJwJoEen",
        "outputId": "30885c45-c726-46cf-bfc7-d0d9a4d41bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data size: 1102426\n",
            "Testing data size: 275607\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df['cleaned_text']\n",
        "Y = df['has_spoiler']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "print(f\"Training data size: {len(X_train)}\")\n",
        "print(f\"Testing data size: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G_wBkj9tmwp",
        "outputId": "279d7f12-e215-4304-ea18-df0b27766968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of empty documents in training set: 0\n",
            "Number of empty documents in testing set: 0\n"
          ]
        }
      ],
      "source": [
        "empty_docs_train = [doc for doc in X_train if len(doc.strip()) == 0]\n",
        "empty_docs_test = [doc for doc in X_test if len(doc.strip()) == 0]\n",
        "\n",
        "print(f\"Number of empty documents in training set: {len(empty_docs_train)}\")\n",
        "print(f\"Number of empty documents in testing set: {len(empty_docs_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a088rdjtm7F",
        "outputId": "7fd0113f-9be8-47cf-f952-71a580e9befb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          review_sentences  \\\n",
            "147051   [[0, Not sure I'm going to write a full review...   \n",
            "1322675  [[0, Hooray this book is finally out!], [0, An...   \n",
            "1221889  [[0, I think I'm losing interest in NA.], [0, ...   \n",
            "1008531  [[0, This book features Michael, the man who d...   \n",
            "859048   [[0, As with the first book in the Kitty Norvi...   \n",
            "399220   [[0, There were a few grammar and sentence lev...   \n",
            "799969   [[0, Amazing urban fantasy.], [0, For once mag...   \n",
            "993745   [[0, Think this would have been perfect just h...   \n",
            "1188494  [[0, I liked Angel Fire more than Angel - whic...   \n",
            "1305916  [[0, Overall a good read!], [0, A little slow ...   \n",
            "\n",
            "                                              cleaned_text  \n",
            "147051   [[0, Not sure I'm going to write a full review...  \n",
            "1322675  [[0, Hooray this book is finally out!], [0, An...  \n",
            "1221889  [[0, I think I'm losing interest in NA.], [0, ...  \n",
            "1008531  [[0, This book features Michael, the man who d...  \n",
            "859048   [[0, As with the first book in the Kitty Norvi...  \n",
            "399220   [[0, There were a few grammar and sentence lev...  \n",
            "799969   [[0, Amazing urban fantasy.], [0, For once mag...  \n",
            "993745   [[0, Think this would have been perfect just h...  \n",
            "1188494  [[0, I liked Angel Fire more than Angel - whic...  \n",
            "1305916  [[0, Overall a good read!], [0, A little slow ...  \n"
          ]
        }
      ],
      "source": [
        "sample_size = 10\n",
        "sample_data = df[['review_sentences', 'cleaned_text']].sample(n=sample_size, random_state=42)\n",
        "\n",
        "print(sample_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7pdqn58tnF_",
        "outputId": "10df863c-ba93-4120-db15-ebce9bc9c144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training TF-IDF matrix shape: (1378033, 10000)\n",
            "Testing TF-IDF matrix shape: (1378033, 10000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "\n",
        "# Fit the vectorizer on the training data and transform both training and testing data\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Training TF-IDF matrix shape: {X_train_tfidf.shape}\")\n",
        "print(f\"Testing TF-IDF matrix shape: {X_test_tfidf.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0QqURMqzdhb",
        "outputId": "b44b7d76-b627-4307-f514-04362fdd0902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train_tfidf: (1102426, 10000)\n",
            "Shape of y_train: 1102426\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'df' is your original DataFrame with 'cleaned_text' and 'spoiler' columns.\n",
        "\n",
        "# Filter out rows where the cleaned_text is empty\n",
        "df_filtered = df[df['cleaned_text'].str.strip() != '']\n",
        "\n",
        "# Reset index for consistency\n",
        "df_filtered.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Prepare features and labels\n",
        "X = df_filtered['cleaned_text']  # Text data\n",
        "y = df_filtered['has_spoiler']  # Spoiler labels\n",
        "\n",
        "# Now split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to list of strings if they are not already\n",
        "X_train = X_train.astype(str).tolist()\n",
        "X_test = X_test.astype(str).tolist()\n",
        "\n",
        "# Transform the training and testing data into TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Check the shapes again\n",
        "print(f\"Shape of X_train_tfidf: {X_train_tfidf.shape}\")  # Should match y_train\n",
        "print(f\"Shape of y_train: {len(Y_train)}\")  # Should now match X_train_tfidf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZoVOw4hym5w",
        "outputId": "f201d814-01db-4f85-eb03-ea51b83da5f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train_tfidf: (1378033, 10000)\n",
            "Shape of Y_train: 1102426\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"Shape of X_train_tfidf: {X_train_tfidf.shape}\")  # Features\n",
        "print(f\"Shape of Y_train: {len(Y_train)}\")  # Labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9natcOtwjcc",
        "outputId": "b41c74f4-a389-4c71-b57a-d94ba5b2dbd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9356801532617096\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.94      0.99      0.97    257570\n",
            "        True       0.55      0.09      0.16     18037\n",
            "\n",
            "    accuracy                           0.94    275607\n",
            "   macro avg       0.75      0.54      0.56    275607\n",
            "weighted avg       0.91      0.94      0.91    275607\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model = LogisticRegression(max_iter=100, verbose=1)\n",
        "model.fit(X_train_tfidf, Y_train)\n",
        "\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "report = classification_report(Y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
